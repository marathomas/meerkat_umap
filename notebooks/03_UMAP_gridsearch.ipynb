{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b8abf2",
   "metadata": {},
   "source": [
    "# Calculate UMAP embeddings with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7c0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas.core.common import flatten\n",
    "import pickle\n",
    "import umap\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b80aad-90e6-4619-aabf-c4fd0c2a4145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daedfea3-54bf-4287-aef4-b52d1a78e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_functions import calc_zscore, pad_spectro, create_padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16f03b4-0e81-4b6b-9b14-8313f1b43043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_functions import preprocess_spec_numba,preprocess_spec_numba_fl, pad_transform_spectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5860022-8a77-4bbd-b081-9440cb44c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectrogramming_functions import generate_mel_spectrogram, generate_stretched_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc828ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "\n",
    "DF = os.path.join(os.path.sep, str(Path(wd).parents[0]), \"data\", \"processed\", \"df_focal_reduced.pkl\")\n",
    "OUT_COORDS = os.path.join(os.path.sep, str(Path(wd).parents[0]), \"data\", \"interim\", \"parameter_search\", \"grid_search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ead17c-fb37-4f6f-8148-aac9b2b99c13",
   "metadata": {},
   "source": [
    "## Generate dataframe for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fea8c5dd-d7f2-415a-9850-e7780dd7d9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6430, 34)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_df = pd.read_pickle(DF)\n",
    "spec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "537c7983-67a0-4557-a1cb-21d7bbd61499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass filters for calculating audio intensity\n",
    "LOWCUT = 300.0\n",
    "HIGHCUT = 3000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f63ad58d-1ecf-47a8-aa3a-3169d6ab8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates intensity score from \n",
    "# amplitude audio data\n",
    "# Input: 1D numeric numpy array (audio data)\n",
    "# Output: Float (Intensity)\n",
    "def calc_audio_intense_score(audio):\n",
    "    res = 10*math.log((np.mean(audio**2)),10)\n",
    "    return res\n",
    "\n",
    "# Butter bandpass filter implementation:\n",
    "# from https://scipy-cookbook.readthedocs.io/items/ButterworthBandpass.html\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86c1d40a-a3dd-4c64-ac1b-81947a87ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectrogramming_functions import generate_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20142177-71ea-404a-be80-d0e988705a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the band-pass filtered signal! \n",
    "raw_audios = spec_df['raw_audio']\n",
    "srs = spec_df['samplerate_hz']\n",
    "\n",
    "audio_filtered = [butter_bandpass_filter(audio, LOWCUT, HIGHCUT, sr, order=6) for audio,sr in zip(raw_audios, srs)]\n",
    "spec_df['raw_audio_filtered'] = audio_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df4114c-6fa4-49cc-b4a2-b076f71a544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogramming parameters\n",
    "FFT_WIN = 0.03 # FFT_WIN*samplerate = length of fft/n_fft (number of audio frames that go in one fft)\n",
    "FFT_HOP = FFT_WIN/8 # FFT_HOP*samplerate = n of audio frames between successive ffts\n",
    "N_MELS = 40 # number of mel bins\n",
    "WINDOW = 'hann' # each frame of audio is windowed by a window function (its length can also be\n",
    "# determined and is then padded with zeros to match n_fft. we use window_length = length of fft\n",
    "FMAX = 4000\n",
    "N_MFCC = 13\n",
    "MAX_DURATION = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d5b067-dc23-4b72-a304-05175df0d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_specs = spec_df.apply(lambda row: generate_spectrogram(row['raw_audio'],\n",
    "                                                           row['samplerate_hz'],\n",
    "                                                           WINDOW,\n",
    "                                                           FFT_WIN,\n",
    "                                                           FFT_HOP), \n",
    "                        axis=1)\n",
    "spec_df['raw_specs'] = raw_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a62de5ce-81b4-41c3-8c90-2867d119b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_specs_filtered = spec_df.apply(lambda row: generate_spectrogram(row['raw_audio_filtered'],\n",
    "                                                                    row['samplerate_hz'],\n",
    "                                                                    WINDOW,\n",
    "                                                                    FFT_WIN,\n",
    "                                                                    FFT_HOP), \n",
    "                                   axis=1)\n",
    "spec_df['raw_specs_filtered'] = raw_specs_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93066505-70bd-4626-9fd2-7556f053291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_specs_stretched = spec_df.apply(lambda row: generate_stretched_spectrogram(row['raw_audio'],\n",
    "                                                                               row['samplerate_hz'],\n",
    "                                                                               row['duration_s'],\n",
    "                                                                               WINDOW,\n",
    "                                                                               FFT_WIN,\n",
    "                                                                               FFT_HOP,\n",
    "                                                                               MAX_DURATION), \n",
    "                                    axis=1)\n",
    "spec_df['raw_specs_stretched'] = raw_specs_stretched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa262866-7d7d-4d02-910a-9ffc46bb2165",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_specs_filtered_stretched = spec_df.apply(lambda row: generate_stretched_spectrogram(row['raw_audio_filtered'],\n",
    "                                                                                        row['samplerate_hz'],\n",
    "                                                                                        row['duration_s'],\n",
    "                                                                                        WINDOW,\n",
    "                                                                                        FFT_WIN,\n",
    "                                                                                        FFT_HOP,\n",
    "                                                                                        MAX_DURATION), \n",
    "                                             axis=1)\n",
    "spec_df['raw_specs_filtered_stretched'] = raw_specs_filtered_stretched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "781cb7cb-d139-432d-9136-4a9e5c9ab020",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df.to_pickle(os.path.join(os.path.sep, str(Path(wd).parents[0]), \"data\", \"processed\", \"df_grid.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396545a2",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbe3e4c-5956-40f9-87a3-68ce3b516d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def unpack_specs(a,b):\n",
    "    \"\"\"\n",
    "    Function that unpacks two specs that have been transformed into \n",
    "    a 1D array with preprocessing_functions.pad_transform_spec and \n",
    "    restores their original 2D shape\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a,b : 1D numpy arrays (numeric)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    spec_s, spec_l : 2D numpy arrays (numeric)\n",
    "                     the restored specs \n",
    "    Example\n",
    "    -------\n",
    "    >>> \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    a_shape0 = int(a[0])\n",
    "    a_shape1 = int(a[1])\n",
    "    b_shape0 = int(b[0])\n",
    "    b_shape1 = int(b[1])\n",
    "\n",
    "    spec_a= np.reshape(a[2:(a_shape0*a_shape1)+2], (a_shape0, a_shape1))\n",
    "    spec_b= np.reshape(b[2:(b_shape0*b_shape1)+2], (b_shape0, b_shape1))\n",
    "    \n",
    "    len_a = a_shape1\n",
    "    len_b = b_shape1\n",
    "    \n",
    "    # find bigger spec\n",
    "    spec_s = spec_a\n",
    "    spec_l = spec_b\n",
    "\n",
    "    if len_a>len_b:\n",
    "        spec_s = spec_b\n",
    "        spec_l = spec_a\n",
    "        \n",
    "    return spec_s, spec_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc9395a1-1235-4994-8ed9-1e7ce3652b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df = pd.read_pickle(os.path.join(os.path.sep, str(Path(wd).parents[0]), \"data\", \"processed\", \"df_grid.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb9a7e6-1c6f-4da5-9505-34e5d076c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEF_PREPROCESS_TYPE = 'zs'\n",
    "DEF_METRIC_TYPE = 'euclidean'\n",
    "DEF_DURATION_METHOD = 'pad'\n",
    "DEF_MIN_DIST = 0\n",
    "DEF_SPREAD = 1\n",
    "DEF_N_NEIGHBORS = 15\n",
    "DEF_N_COMPS = 3\n",
    "DEF_DENOISE = 'no'\n",
    "DEF_N_MELS = 40\n",
    "DEF_F_UNIT = 'dB'\n",
    "\n",
    "# Spectrogramming parameters\n",
    "FFT_WIN = 0.03 # FFT_WIN*samplerate = length of fft/n_fft (number of audio frames that go in one fft)\n",
    "FFT_HOP = FFT_WIN/8 # FFT_HOP*samplerate = n of audio frames between successive ffts\n",
    "N_MELS = 40 # number of mel bins\n",
    "WINDOW = 'hann' # each frame of audio is windowed by a window function (its length can also be\n",
    "# determined and is then padded with zeros to match n_fft. we use window_length = length of fft\n",
    "FMAX = 4000\n",
    "N_MFCC = 13\n",
    "MAX_DURATION = 0.5\n",
    "MIN_OVERLAP = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f675de1-d61c-46f6-8515-4e3ed6f41355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import correlation\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "438ee331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_string():\n",
    "    param_combi = \"_\".join([str(x) for x in [preprocess_type, metric_type, duration_method,\n",
    "                                             min_dist, spread, n_neighbors, n_comps, input_type, \n",
    "                                             denoise, n_mels, f_unit, bp_filtered]])\n",
    "    return param_combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "941699ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_umap(data, outname, metric=DEF_METRIC_TYPE, min_dist=DEF_MIN_DIST, spread=DEF_SPREAD, n_neighbors=DEF_N_NEIGHBORS, n_comps=DEF_N_COMPS,n = 1):\n",
    "    \n",
    "    for i in range(n):\n",
    "        reducer = umap.UMAP(n_components = n_comps, \n",
    "                            min_dist=min_dist,\n",
    "                            spread=spread,\n",
    "                            n_neighbors=n_neighbors,\n",
    "                            metric=metric,\n",
    "                            random_state=2204)\n",
    "\n",
    "        embedding = reducer.fit_transform(data)\n",
    "        print(\"\\r\"+outname, end=\"\")\n",
    "        np.savetxt(outname+'_'+str(i)+'.csv', embedding, delimiter=\";\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9957b80e-88fc-4a8a-8217-405eb14e1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** DO THE FULL GRIDSEARCH ***************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e10b50-8b8f-4499-8f43-361295a300f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = DEF_N_NEIGHBORS\n",
    "spread = DEF_SPREAD\n",
    "min_dist = DEF_MIN_DIST\n",
    "n_comps = 3\n",
    "input_type = \"specs\"\n",
    "\n",
    "FMAX = 4000\n",
    "\n",
    "for duration_method in ['pad', 'pairwise-pad', 'stretched', 'timeshift-pad', 'timeshift-overlap', 'overlap']:\n",
    "    for preprocess_type in ['no', 'zs', 'zs-fl-ce']:\n",
    "        for metric_type in ['cosine', 'euclidean', 'correlation', 'manhattan']:\n",
    "            for denoise in ['yes', 'no']:\n",
    "                for n_mels in [0, 10, 20, 30, 40, 50]:\n",
    "                    for f_unit in ['dB', 'magnitude']:\n",
    "                        for bp_filtered in ['yes', 'no']:                            \n",
    "                            outname = os.path.join(os.path.sep, OUT_COORDS, get_param_string())\n",
    "                            #print(\"\\r\"+outname, end=\"\")                   \n",
    "                            try:\n",
    "                                # select dataframe column\n",
    "                                if bp_filtered=='yes':\n",
    "                                    if duration_method=='stretched':\n",
    "                                        specs = spec_df.raw_specs_filtered_stretched.copy()\n",
    "                                    else:\n",
    "                                        specs = spec_df.raw_specs_filtered.copy()\n",
    "                                else:\n",
    "                                    if duration_method=='stretched':\n",
    "                                        specs = spec_df.raw_specs_stretched.copy()\n",
    "                                    else:\n",
    "                                        specs = spec_df.raw_specs.copy()\n",
    "\n",
    "\n",
    "                                # Mel transform\n",
    "                                if n_mels>0:\n",
    "                                    srs = spec_df.samplerate_hz.copy()\n",
    "                                    specs = [librosa.feature.melspectrogram(S=s, sr=sr, n_mels=n_mels, fmax=FMAX) for s, sr in zip(specs, srs)]\n",
    "                                else:\n",
    "                                    # Problem: Because of the varying samplerate, the non-mel-transformed spectrograms are not all of the same height!!\n",
    "                                    # So if I'm using them, I need to cut the ones with the more frequency range.\n",
    "                                    n_bins = [s.shape[0] for s in specs]\n",
    "                                    min_bins = np.min(n_bins)\n",
    "                                    specs = [s[0:min_bins,:] for s in specs]\n",
    "\n",
    "                                # Spectrogram intensity unit\n",
    "                                if f_unit==\"dB\":\n",
    "                                    specs = [librosa.power_to_db(s, ref=np.max) for s in specs]\n",
    "\n",
    "\n",
    "                                # Denoising\n",
    "                                if denoise=='yes':\n",
    "                                    specs = [(s-np.median(s, axis=0)) for s in specs]\n",
    "\n",
    "                                # Pre-processing\n",
    "                                if preprocess_type=='zs':\n",
    "                                    specs = [calc_zscore(s) for s in specs]\n",
    "                                elif preprocess_type=='zs-fl-ce':\n",
    "                                    specs = [calc_zscore(s) for s in specs] \n",
    "                                    specs = [np.where(s<0,0,s) for s in specs]\n",
    "                                    specs = [np.where(s>3,3,s) for s in specs]\n",
    "\n",
    "\n",
    "                                # Duration method\n",
    "                                if duration_method in ['pad', 'stretched']:\n",
    "                                    data = create_padded_data(specs)\n",
    "                                    calc_umap(data, outname=outname, metric = metric_type)\n",
    "\n",
    "                                else:\n",
    "                                    n_bins = specs[0].shape[0]\n",
    "                                    maxlen = np.max([spec.shape[1] for spec in specs]) * n_bins + 2\n",
    "                                    trans_specs = [pad_transform_spectro(spec, maxlen) for spec in specs]\n",
    "                                    data = np.asarray(trans_specs)\n",
    "\n",
    "\n",
    "                                    # set spec_dist depending on metric_type!!\n",
    "                                    if metric_type=='euclidean':\n",
    "                                        @numba.njit()\n",
    "                                        def spec_dist(a,b,size):\n",
    "                                            dist = np.sqrt((np.sum(np.subtract(a,b)*np.subtract(a,b)))) / np.sqrt(size)\n",
    "                                            return dist\n",
    "\n",
    "                                    elif metric_type=='manhattan':\n",
    "                                        @numba.njit()\n",
    "                                        def spec_dist(a,b,size):\n",
    "                                            dist = (np.sum(np.abs(np.subtract(a,b)))) / size\n",
    "                                            return dist\n",
    "\n",
    "                                    elif metric_type=='cosine':\n",
    "                                        @numba.njit()\n",
    "                                        def spec_dist(a,b,size):\n",
    "                                            # turn into unit vectors by dividing each vector field by magnitude of vector\n",
    "                                            dot_product = np.sum(a*b)\n",
    "                                            a_magnitude = np.sqrt(np.sum(a*a))\n",
    "                                            b_magnitude = np.sqrt(np.sum(b*b))\n",
    "                                            dist = 1 - dot_product/(a_magnitude*b_magnitude)\n",
    "                                            return dist\n",
    "\n",
    "                                    elif metric_type=='correlation':\n",
    "                                        @numba.njit()\n",
    "                                        def spec_dist(a,b,size):\n",
    "                                            a_meandiff = a - np.mean(a)\n",
    "                                            b_meandiff = b - np.mean(b)\n",
    "                                            dot_product =  np.sum(a_meandiff*b_meandiff)                                  \n",
    "                                            a_meandiff_magnitude = np.sqrt(np.sum(a_meandiff*a_meandiff))\n",
    "                                            b_meandiff_magnitude = np.sqrt(np.sum(b_meandiff*b_meandiff))\n",
    "                                            dist = 1 - dot_product/(a_meandiff_magnitude * b_meandiff_magnitude)\n",
    "                                            return dist\n",
    "                                    \n",
    "                                    \n",
    "                                    # for duration_method in ['pad', 'pairwise-pad', 'stretch', 'timeshift-pad', 'timeshift-overlap', 'overlap']:\n",
    "                                    if duration_method=='pairwise-pad':\n",
    "                                        @numba.njit()\n",
    "                                        def calc_pairwise_pad(a, b):\n",
    "                                            spec_s, spec_l = unpack_specs(a,b)\n",
    "                                            n_padding = int(spec_l.shape[1] - spec_s.shape[1])\n",
    "\n",
    "                                            n_bins = spec_s.shape[0]\n",
    "\n",
    "                                                    # pad the smaller spec (if necessary)\n",
    "                                            if n_padding!=0:\n",
    "                                                pad = np.full((n_bins, n_padding), 0.0)\n",
    "                                                spec_s_padded = np.concatenate((spec_s, pad), axis=1)\n",
    "                                                spec_s_padded = spec_s_padded.astype(np.float64)\n",
    "                                            else:\n",
    "                                                spec_s_padded = spec_s.astype(np.float64)\n",
    "\n",
    "                                                    # compute distance\n",
    "\n",
    "                                            spec_s_padded = np.reshape(spec_s_padded, (-1)).astype(np.float64)\n",
    "                                            spec_l = np.reshape(spec_l, (-1)).astype(np.float64)\n",
    "                                            size = spec_l.shape[0]\n",
    "\n",
    "                                            dist = spec_dist(spec_s_padded, spec_l, size)\n",
    "                                            return dist\n",
    "\n",
    "                                        calc_umap(data, outname=outname, metric = calc_pairwise_pad)\n",
    "\n",
    "                                    elif duration_method=='timeshift-pad':\n",
    "                                        @numba.njit()\n",
    "                                        def calc_timeshift_pad(a,b):\n",
    "                                            spec_s, spec_l = unpack_specs(a,b)\n",
    "\n",
    "                                            len_s = spec_s.shape[1]\n",
    "                                            len_l = spec_l.shape[1]\n",
    "\n",
    "                                            nfreq = spec_s.shape[0] \n",
    "\n",
    "                                                # define start position\n",
    "                                            min_overlap_frames = int(MIN_OVERLAP * len_s)\n",
    "                                            start_timeline = min_overlap_frames-len_s\n",
    "                                            max_timeline = len_l - min_overlap_frames\n",
    "\n",
    "                                            n_of_calculations = int((((max_timeline+1-start_timeline)+(max_timeline+1-start_timeline))/2) +1)\n",
    "\n",
    "                                            distances = np.full((n_of_calculations),999.)\n",
    "\n",
    "                                            count=0\n",
    "\n",
    "                                            for timeline_p in range(start_timeline, max_timeline+1,2):\n",
    "                                                    #print(\"timeline: \", timeline_p)\n",
    "                                                    # mismatch on left side\n",
    "                                                if timeline_p < 0:\n",
    "                                                    len_overlap = len_s - abs(timeline_p)\n",
    "                                                    pad_s = np.full((nfreq, (len_l-len_overlap)),0.)\n",
    "                                                    pad_l = np.full((nfreq, (len_s-len_overlap)),0.)\n",
    "\n",
    "                                                    s_config = np.append(spec_s, pad_s, axis=1).astype(np.float64)\n",
    "                                                    l_config = np.append(pad_l, spec_l, axis=1).astype(np.float64)\n",
    "\n",
    "                                                    # mismatch on right side\n",
    "                                                elif timeline_p > (len_l-len_s):\n",
    "\n",
    "                                                    len_overlap = len_l - timeline_p\n",
    "\n",
    "                                                    pad_s = np.full((nfreq, (len_l-len_overlap)),0.)\n",
    "                                                    pad_l = np.full((nfreq, (len_s-len_overlap)),0.)\n",
    "\n",
    "                                                    s_config = np.append(pad_s, spec_s, axis=1).astype(np.float64)\n",
    "                                                    l_config = np.append(spec_l, pad_l, axis=1).astype(np.float64)\n",
    "\n",
    "                                                    # no mismatch on either side\n",
    "                                                else:\n",
    "                                                    len_overlap = len_s\n",
    "                                                    start_col_l = timeline_p\n",
    "                                                    end_col_l = start_col_l + len_overlap\n",
    "\n",
    "                                                    pad_s_left = np.full((nfreq, start_col_l),0.)\n",
    "                                                    pad_s_right = np.full((nfreq, (len_l - end_col_l)),0.)\n",
    "\n",
    "                                                    l_config = spec_l.astype(np.float64)\n",
    "                                                    s_config = np.append(pad_s_left, spec_s, axis=1).astype(np.float64)\n",
    "                                                    s_config = np.append(s_config, pad_s_right, axis=1).astype(np.float64)\n",
    "\n",
    "                                                size = s_config.shape[0]*s_config.shape[1]\n",
    "                                                distances[count] = spec_dist(s_config, l_config, size)\n",
    "                                                count = count + 1\n",
    "\n",
    "\n",
    "                                            min_dist = np.min(distances)\n",
    "                                            return min_dist\n",
    "                                            \n",
    "                                        calc_umap(data, outname=outname, metric = calc_timeshift_pad)\n",
    "\n",
    "\n",
    "                                    elif duration_method=='timeshift-overlap':\n",
    "                                        @numba.njit()\n",
    "                                        def calc_timeshift(a,b):\n",
    "                                            spec_s, spec_l = unpack_specs(a,b)  \n",
    "                                            len_l = spec_l.shape[1]\n",
    "                                            len_s = spec_s.shape[1]\n",
    "\n",
    "\n",
    "                                                # define start position\n",
    "                                            min_overlap_frames = int(MIN_OVERLAP * len_s)\n",
    "                                            start_timeline = min_overlap_frames-len_s\n",
    "                                            max_timeline = len_l - min_overlap_frames\n",
    "\n",
    "                                            n_of_calculations = (max_timeline+1-start_timeline)+(max_timeline+1-start_timeline)\n",
    "\n",
    "                                            distances = np.full((n_of_calculations),999.)\n",
    "\n",
    "                                            count=0\n",
    "\n",
    "                                            for timeline_p in range(start_timeline, max_timeline+1):\n",
    "                                                    # mismatch on left side\n",
    "                                                if timeline_p < 0:\n",
    "                                                    start_col_l = 0\n",
    "                                                    len_overlap = len_s - abs(timeline_p)\n",
    "\n",
    "                                                    end_col_l = start_col_l + len_overlap\n",
    "\n",
    "                                                    end_col_s = len_s # until the end\n",
    "                                                    start_col_s = end_col_s - len_overlap\n",
    "\n",
    "                                                    # mismatch on right side\n",
    "                                                elif timeline_p > (len_l-len_s):\n",
    "                                                    start_col_l = timeline_p\n",
    "                                                    len_overlap = len_l - timeline_p\n",
    "                                                    end_col_l = len_l\n",
    "\n",
    "                                                    start_col_s = 0\n",
    "                                                    end_col_s = start_col_s + len_overlap\n",
    "\n",
    "                                                    # no mismatch on either side\n",
    "                                                else:\n",
    "                                                    start_col_l = timeline_p\n",
    "                                                    len_overlap = len_s\n",
    "                                                    end_col_l = start_col_l + len_overlap\n",
    "\n",
    "                                                    start_col_s = 0\n",
    "                                                    end_col_s = len_s # until the end\n",
    "\n",
    "\n",
    "                                                s_s = spec_s[:,start_col_s:end_col_s].astype(np.float64)\n",
    "                                                s_l = spec_l[:,start_col_l:end_col_l].astype(np.float64)\n",
    "                                                size = s_s.shape[0]*s_s.shape[1]\n",
    "                                                distances[count] = spec_dist(s_s, s_l, size)\n",
    "\n",
    "                                                count = count + 1\n",
    "\n",
    "                                            min_dist = np.min(distances)                                              \n",
    "                                            return min_dist\n",
    "                                        \n",
    "                                        calc_umap(data, outname=outname, metric = calc_timeshift)\n",
    "\n",
    "\n",
    "                                    elif duration_method=='overlap':\n",
    "                                        @numba.njit()\n",
    "                                        def calc_overlap_only(a,b): \n",
    "                                            spec_s, spec_l = unpack_specs(a,b)\n",
    "\n",
    "                                                #only use overlap section from longer spec\n",
    "                                            spec_l = spec_l[:spec_s.shape[0],:spec_s.shape[1]]\n",
    "\n",
    "                                            spec_s = spec_s.astype(np.float64)\n",
    "                                            spec_l = spec_l.astype(np.float64)\n",
    "\n",
    "                                            size = spec_s.shape[1]*spec_s.shape[0]   \n",
    "                                            dist = spec_dist(spec_s, spec_l, size)\n",
    "\n",
    "                                            return dist\n",
    "                                            \n",
    "                                        calc_umap(data, outname=outname, metric = calc_overlap_only)\n",
    "                                    \n",
    "                            except:\n",
    "                                print(\"FAILED: \", get_param_string())\n",
    "                                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a34001-fef0-4e64-80e0-0018396051eb",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fbdf757-6359-47c6-abb8-cce8d4a463f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:  3456\n",
      "Observed:  3438\n",
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_yes_10_magnitude_yes_0.csv',\n",
       " 'zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_yes_10_magnitude_no_0.csv',\n",
       " 'zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_10_magnitude_yes_0.csv',\n",
       " 'zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_10_magnitude_no_0.csv',\n",
       " 'zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_20_magnitude_yes_0.csv',\n",
       " 'zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_20_magnitude_no_0.csv',\n",
       " 'zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_30_magnitude_yes_0.csv',\n",
       " 'zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_30_magnitude_no_0.csv',\n",
       " 'zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_40_magnitude_no_0.csv',\n",
       " 'zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_yes_10_magnitude_yes_0.csv',\n",
       " 'zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_yes_10_magnitude_no_0.csv',\n",
       " 'zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_10_magnitude_yes_0.csv',\n",
       " 'zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_10_magnitude_no_0.csv',\n",
       " 'zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_20_magnitude_yes_0.csv',\n",
       " 'zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_20_magnitude_no_0.csv',\n",
       " 'zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_30_magnitude_yes_0.csv',\n",
       " 'zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_30_magnitude_no_0.csv',\n",
       " 'zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_40_magnitude_no_0.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = DEF_N_NEIGHBORS\n",
    "spread = DEF_SPREAD\n",
    "min_dist = DEF_MIN_DIST\n",
    "n_comps = 3\n",
    "input_type = \"specs\"\n",
    "FMAX = 4000\n",
    "\n",
    "expected_files = []\n",
    "\n",
    "for duration_method in ['pad', 'pairwise-pad', 'stretched', 'timeshift-pad', 'timeshift-overlap', 'overlap']:\n",
    "    for preprocess_type in ['no', 'zs', 'zs-fl-ce']:\n",
    "        for metric_type in ['cosine', 'euclidean', 'correlation', 'manhattan']:\n",
    "            for denoise in ['yes', 'no']:\n",
    "                for n_mels in [0, 10, 20, 30, 40, 50]:\n",
    "                    for f_unit in ['dB', 'magnitude']:\n",
    "                        for bp_filtered in ['yes', 'no']:                            \n",
    "                            expected_files.append(get_param_string()+'_0.csv')\n",
    "print('Expected: ',len(expected_files))\n",
    "\n",
    "all_embedding_files = list(sorted(os.listdir(OUT_COORDS)))\n",
    "print('Observed: ',len(all_embedding_files))\n",
    "\n",
    "missing_in_observed = [x for x in expected_files if x not in all_embedding_files]\n",
    "print(len(missing_in_observed))\n",
    "missing_in_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9df4dde3-0b0b-44bb-af2b-e026a8f69bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_from_filename(embedding_file):\n",
    "    embedding_params_string = embedding_file.replace('.csv', '')\n",
    "    embedding_params_list = embedding_params_string.split('_')\n",
    "    return embedding_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "156cc353-3df1-4236-828b-5417c5373d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_yes_10_magnitude_yes_0.csv\n"
     ]
    }
   ],
   "source": [
    "for f in missing_in_observed[:1]:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d37f326a-cb16-4d83-a51b-9b5df7dac658",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_type, metric_type, duration_method,min_dist, spread, n_neighbors, n_comps, input_type, denoise, n_mels, f_unit, bp_filtered, n_repeat = get_params_from_filename(f)\n",
    "min_dist = int(min_dist)\n",
    "spread = int(spread)\n",
    "n_neighbors = int(n_neighbors)\n",
    "n_comps = int(n_comps)\n",
    "n_mels = int(n_mels)\n",
    "\n",
    "if bp_filtered=='yes':\n",
    "    if duration_method=='stretched':\n",
    "        specs = spec_df.raw_specs_filtered_stretched.copy()\n",
    "    else:\n",
    "        specs = spec_df.raw_specs_filtered.copy()\n",
    "else:\n",
    "    if duration_method=='stretched':\n",
    "        specs = spec_df.raw_specs_stretched.copy()\n",
    "    else:\n",
    "        specs = spec_df.raw_specs.copy()\n",
    "        \n",
    "if n_mels>0:\n",
    "    srs = spec_df.samplerate_hz.copy()\n",
    "    specs = [librosa.feature.melspectrogram(S=s, sr=sr, n_mels=n_mels, fmax=FMAX) for s, sr in zip(specs, srs)]\n",
    "else:\n",
    "                                    # Problem: Because of the varying samplerate, the non-mel-transformed spectrograms are not all of the same height!!\n",
    "                                    # So if I'm using them, I need to cut the ones with the more frequency range.\n",
    "    n_bins = [s.shape[0] for s in specs]\n",
    "    min_bins = np.min(n_bins)\n",
    "    specs = [s[0:min_bins,:] for s in specs]\n",
    "    \n",
    "if denoise=='yes':\n",
    "        specs = [(s-np.median(s, axis=0)) for s in specs] \n",
    "    \n",
    "#if preprocess_type=='zs':\n",
    "#    specs = [calc_zscore(s) for s in specs]\n",
    "if preprocess_type=='zs-fl-ce':\n",
    "    specs = [calc_zscore(s) for s in specs] \n",
    "    specs = [np.where(s<0,0,s) for s in specs]\n",
    "    specs = [np.where(s>3,3,s) for s in specs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc3a5971-66a9-4e62-b48b-f36b48a1425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   38   39   40   41  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    42   43   44   45   46   47  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 48 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=specs[0]\n",
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0d309bb-fcb4-4051-a605-ec2959ed93cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6b2a5df-d4d4-4053-b966-12dd357b5d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b5f53a1-710f-4d7f-8e4c-7525d7a4b0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n, bins, pathc = plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8efaff68-082b-49fe-98bc-bcf3a37b0069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.290069</td>\n",
       "      <td>-0.290612</td>\n",
       "      <td>-0.283019</td>\n",
       "      <td>-0.283077</td>\n",
       "      <td>-0.286794</td>\n",
       "      <td>-0.291003</td>\n",
       "      <td>-0.293264</td>\n",
       "      <td>-0.290946</td>\n",
       "      <td>-0.289902</td>\n",
       "      <td>-0.297465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312240</td>\n",
       "      <td>-0.298891</td>\n",
       "      <td>-0.292233</td>\n",
       "      <td>-0.292414</td>\n",
       "      <td>-0.289245</td>\n",
       "      <td>-0.294706</td>\n",
       "      <td>-0.311008</td>\n",
       "      <td>-0.334730</td>\n",
       "      <td>-0.348320</td>\n",
       "      <td>-0.335536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.279069</td>\n",
       "      <td>-0.274775</td>\n",
       "      <td>-0.254804</td>\n",
       "      <td>-0.243103</td>\n",
       "      <td>-0.245293</td>\n",
       "      <td>-0.257877</td>\n",
       "      <td>-0.269018</td>\n",
       "      <td>-0.267264</td>\n",
       "      <td>-0.252271</td>\n",
       "      <td>-0.200452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264588</td>\n",
       "      <td>-0.275326</td>\n",
       "      <td>-0.277507</td>\n",
       "      <td>-0.263634</td>\n",
       "      <td>-0.237738</td>\n",
       "      <td>-0.237523</td>\n",
       "      <td>-0.259580</td>\n",
       "      <td>-0.276654</td>\n",
       "      <td>-0.270864</td>\n",
       "      <td>-0.245433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.287888</td>\n",
       "      <td>-0.285584</td>\n",
       "      <td>-0.269606</td>\n",
       "      <td>-0.256605</td>\n",
       "      <td>-0.251463</td>\n",
       "      <td>-0.260878</td>\n",
       "      <td>-0.276584</td>\n",
       "      <td>-0.275854</td>\n",
       "      <td>-0.251166</td>\n",
       "      <td>-0.193290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219814</td>\n",
       "      <td>-0.234264</td>\n",
       "      <td>-0.253356</td>\n",
       "      <td>-0.275931</td>\n",
       "      <td>-0.288711</td>\n",
       "      <td>-0.294610</td>\n",
       "      <td>-0.293224</td>\n",
       "      <td>-0.298060</td>\n",
       "      <td>-0.310674</td>\n",
       "      <td>-0.308354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.237430</td>\n",
       "      <td>-0.250928</td>\n",
       "      <td>-0.267243</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.284000</td>\n",
       "      <td>-0.284910</td>\n",
       "      <td>-0.282670</td>\n",
       "      <td>-0.275408</td>\n",
       "      <td>-0.272398</td>\n",
       "      <td>-0.269956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266002</td>\n",
       "      <td>-0.254854</td>\n",
       "      <td>-0.259896</td>\n",
       "      <td>-0.282029</td>\n",
       "      <td>-0.294470</td>\n",
       "      <td>-0.286510</td>\n",
       "      <td>-0.259346</td>\n",
       "      <td>-0.248446</td>\n",
       "      <td>-0.273353</td>\n",
       "      <td>-0.293334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.275599</td>\n",
       "      <td>-0.283563</td>\n",
       "      <td>-0.290150</td>\n",
       "      <td>-0.296579</td>\n",
       "      <td>-0.295389</td>\n",
       "      <td>-0.291566</td>\n",
       "      <td>-0.289703</td>\n",
       "      <td>-0.286530</td>\n",
       "      <td>-0.275142</td>\n",
       "      <td>-0.171416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172408</td>\n",
       "      <td>-0.265948</td>\n",
       "      <td>-0.280537</td>\n",
       "      <td>-0.289102</td>\n",
       "      <td>-0.285875</td>\n",
       "      <td>-0.273711</td>\n",
       "      <td>-0.268983</td>\n",
       "      <td>-0.293110</td>\n",
       "      <td>-0.328973</td>\n",
       "      <td>-0.335760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.292684</td>\n",
       "      <td>-0.294212</td>\n",
       "      <td>-0.288275</td>\n",
       "      <td>-0.287225</td>\n",
       "      <td>-0.286478</td>\n",
       "      <td>-0.286294</td>\n",
       "      <td>-0.288254</td>\n",
       "      <td>-0.289096</td>\n",
       "      <td>-0.288054</td>\n",
       "      <td>-0.280492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267266</td>\n",
       "      <td>-0.282149</td>\n",
       "      <td>-0.288780</td>\n",
       "      <td>-0.295140</td>\n",
       "      <td>-0.296049</td>\n",
       "      <td>-0.296608</td>\n",
       "      <td>-0.296930</td>\n",
       "      <td>-0.302321</td>\n",
       "      <td>-0.304604</td>\n",
       "      <td>-0.288489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.281481</td>\n",
       "      <td>-0.287345</td>\n",
       "      <td>-0.289682</td>\n",
       "      <td>-0.293355</td>\n",
       "      <td>-0.291601</td>\n",
       "      <td>-0.287748</td>\n",
       "      <td>-0.287267</td>\n",
       "      <td>-0.288861</td>\n",
       "      <td>-0.292908</td>\n",
       "      <td>-0.300617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310690</td>\n",
       "      <td>-0.297129</td>\n",
       "      <td>-0.289177</td>\n",
       "      <td>-0.288855</td>\n",
       "      <td>-0.286323</td>\n",
       "      <td>-0.289549</td>\n",
       "      <td>-0.289397</td>\n",
       "      <td>-0.266381</td>\n",
       "      <td>-0.214574</td>\n",
       "      <td>-0.154426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.294140</td>\n",
       "      <td>-0.297310</td>\n",
       "      <td>-0.294432</td>\n",
       "      <td>-0.294542</td>\n",
       "      <td>-0.292007</td>\n",
       "      <td>-0.290209</td>\n",
       "      <td>-0.292290</td>\n",
       "      <td>-0.293737</td>\n",
       "      <td>-0.295825</td>\n",
       "      <td>-0.305421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311377</td>\n",
       "      <td>-0.297738</td>\n",
       "      <td>-0.290340</td>\n",
       "      <td>-0.286966</td>\n",
       "      <td>-0.278200</td>\n",
       "      <td>-0.279670</td>\n",
       "      <td>-0.288560</td>\n",
       "      <td>-0.284847</td>\n",
       "      <td>-0.251881</td>\n",
       "      <td>-0.202653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.292918</td>\n",
       "      <td>-0.295145</td>\n",
       "      <td>-0.290479</td>\n",
       "      <td>-0.290731</td>\n",
       "      <td>-0.291163</td>\n",
       "      <td>-0.292497</td>\n",
       "      <td>-0.295132</td>\n",
       "      <td>-0.295391</td>\n",
       "      <td>-0.296822</td>\n",
       "      <td>-0.304637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311136</td>\n",
       "      <td>-0.295808</td>\n",
       "      <td>-0.289533</td>\n",
       "      <td>-0.292961</td>\n",
       "      <td>-0.290981</td>\n",
       "      <td>-0.288408</td>\n",
       "      <td>-0.279220</td>\n",
       "      <td>-0.258828</td>\n",
       "      <td>-0.230839</td>\n",
       "      <td>-0.196974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.296633</td>\n",
       "      <td>-0.299966</td>\n",
       "      <td>-0.297239</td>\n",
       "      <td>-0.297735</td>\n",
       "      <td>-0.296725</td>\n",
       "      <td>-0.297107</td>\n",
       "      <td>-0.300342</td>\n",
       "      <td>-0.301332</td>\n",
       "      <td>-0.302345</td>\n",
       "      <td>-0.311049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316821</td>\n",
       "      <td>-0.302975</td>\n",
       "      <td>-0.297360</td>\n",
       "      <td>-0.300960</td>\n",
       "      <td>-0.301542</td>\n",
       "      <td>-0.306627</td>\n",
       "      <td>-0.315275</td>\n",
       "      <td>-0.322899</td>\n",
       "      <td>-0.316358</td>\n",
       "      <td>-0.289468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.290069 -0.290612 -0.283019 -0.283077 -0.286794 -0.291003 -0.293264   \n",
       "1 -0.279069 -0.274775 -0.254804 -0.243103 -0.245293 -0.257877 -0.269018   \n",
       "2 -0.287888 -0.285584 -0.269606 -0.256605 -0.251463 -0.260878 -0.276584   \n",
       "3 -0.237430 -0.250928 -0.267243 -0.280099 -0.284000 -0.284910 -0.282670   \n",
       "4 -0.275599 -0.283563 -0.290150 -0.296579 -0.295389 -0.291566 -0.289703   \n",
       "5 -0.292684 -0.294212 -0.288275 -0.287225 -0.286478 -0.286294 -0.288254   \n",
       "6 -0.281481 -0.287345 -0.289682 -0.293355 -0.291601 -0.287748 -0.287267   \n",
       "7 -0.294140 -0.297310 -0.294432 -0.294542 -0.292007 -0.290209 -0.292290   \n",
       "8 -0.292918 -0.295145 -0.290479 -0.290731 -0.291163 -0.292497 -0.295132   \n",
       "9 -0.296633 -0.299966 -0.297239 -0.297735 -0.296725 -0.297107 -0.300342   \n",
       "\n",
       "         7         8         9   ...        38        39        40        41  \\\n",
       "0 -0.290946 -0.289902 -0.297465  ... -0.312240 -0.298891 -0.292233 -0.292414   \n",
       "1 -0.267264 -0.252271 -0.200452  ... -0.264588 -0.275326 -0.277507 -0.263634   \n",
       "2 -0.275854 -0.251166 -0.193290  ... -0.219814 -0.234264 -0.253356 -0.275931   \n",
       "3 -0.275408 -0.272398 -0.269956  ... -0.266002 -0.254854 -0.259896 -0.282029   \n",
       "4 -0.286530 -0.275142 -0.171416  ... -0.172408 -0.265948 -0.280537 -0.289102   \n",
       "5 -0.289096 -0.288054 -0.280492  ... -0.267266 -0.282149 -0.288780 -0.295140   \n",
       "6 -0.288861 -0.292908 -0.300617  ... -0.310690 -0.297129 -0.289177 -0.288855   \n",
       "7 -0.293737 -0.295825 -0.305421  ... -0.311377 -0.297738 -0.290340 -0.286966   \n",
       "8 -0.295391 -0.296822 -0.304637  ... -0.311136 -0.295808 -0.289533 -0.292961   \n",
       "9 -0.301332 -0.302345 -0.311049  ... -0.316821 -0.302975 -0.297360 -0.300960   \n",
       "\n",
       "         42        43        44        45        46        47  \n",
       "0 -0.289245 -0.294706 -0.311008 -0.334730 -0.348320 -0.335536  \n",
       "1 -0.237738 -0.237523 -0.259580 -0.276654 -0.270864 -0.245433  \n",
       "2 -0.288711 -0.294610 -0.293224 -0.298060 -0.310674 -0.308354  \n",
       "3 -0.294470 -0.286510 -0.259346 -0.248446 -0.273353 -0.293334  \n",
       "4 -0.285875 -0.273711 -0.268983 -0.293110 -0.328973 -0.335760  \n",
       "5 -0.296049 -0.296608 -0.296930 -0.302321 -0.304604 -0.288489  \n",
       "6 -0.286323 -0.289549 -0.289397 -0.266381 -0.214574 -0.154426  \n",
       "7 -0.278200 -0.279670 -0.288560 -0.284847 -0.251881 -0.202653  \n",
       "8 -0.290981 -0.288408 -0.279220 -0.258828 -0.230839 -0.196974  \n",
       "9 -0.301542 -0.306627 -0.315275 -0.322899 -0.316358 -0.289468  \n",
       "\n",
       "[10 rows x 48 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs_z = [calc_zscore(s) for s in specs]\n",
    "x_z = specs_z[0]\n",
    "pd.DataFrame(x_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8aa2f45e-3cb0-4bf7-bbe7-d717b4f623f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n, bins, pathc = plt.hist(x_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c88e6bf-e884-46e3-bd1c-9da021e6eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = [np.where(s<0,0,s) for s in specs_z]\n",
    "specs = [np.where(s>3,3,s) for s in specs_z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57eb52e9-ba15-4c0c-aa4b-e690c192c7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7137832399749983"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = specs[0]\n",
    "np.min(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54b0fc39-5a9a-4700-b1d7-52ae003fee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_umap(data, outname, metric=DEF_METRIC_TYPE, min_dist=DEF_MIN_DIST, spread=DEF_SPREAD, n_neighbors=DEF_N_NEIGHBORS, n_comps=DEF_N_COMPS,n = 1):\n",
    "    \n",
    "    for i in range(n):\n",
    "        reducer = umap.UMAP(n_components = n_comps, \n",
    "                            min_dist=min_dist,\n",
    "                            spread=spread,\n",
    "                            n_neighbors=n_neighbors,\n",
    "                            metric=metric,\n",
    "                            random_state=1)\n",
    "\n",
    "        embedding = reducer.fit_transform(data)\n",
    "        print(outname)\n",
    "        np.savetxt(outname+'_'+str(i)+'.csv', embedding, delimiter=\";\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3730b121-8d85-4d2c-9e36-fe996829b986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_yes_10_magnitude_yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_yes_10_magnitude_no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_10_magnitude_yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_10_magnitude_no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_20_magnitude_yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_20_magnitude_no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_30_magnitude_yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_30_magnitude_no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_cosine_timeshift-overlap_0_1_15_3_specs_no_40_magnitude_no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_yes_10_magnitude_yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_yes_10_magnitude_no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_10_magnitude_yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_10_magnitude_no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_20_magnitude_yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_20_magnitude_no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_30_magnitude_yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_30_magnitude_no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mthomas/anaconda3/envs/meerkat_umap_env_3/lib/python3.7/site-packages/umap/umap_.py:1728: UserWarning: custom distance metric does not return gradient; inverse_transform will be unavailable. To enable using inverse_transform method method, define a distance function that returns a tuple of (distance [float], gradient [np.array])\n",
      "  \"custom distance metric does not return gradient; inverse_transform will be unavailable. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mthomas/Documents/MPI_work/projects/meerkat/meerkat_umap_pv/data/interim/parameter_search/grid_search/zs-fl-ce_correlation_timeshift-overlap_0_1_15_3_specs_no_40_magnitude_no\n"
     ]
    }
   ],
   "source": [
    "# Re-do missing \n",
    "\n",
    "for f in missing_in_observed:\n",
    "    preprocess_type, metric_type, duration_method,min_dist, spread, n_neighbors, n_comps, input_type, denoise, n_mels, f_unit, bp_filtered, n_repeat = get_params_from_filename(f)\n",
    "    \n",
    "    min_dist = int(min_dist)\n",
    "    spread = int(spread)\n",
    "    n_neighbors = int(n_neighbors)\n",
    "    n_comps = int(n_comps)\n",
    "    n_mels = int(n_mels)\n",
    "    \n",
    "    outname = os.path.join(os.path.sep, OUT_COORDS, get_param_string())\n",
    "    \n",
    "    try:\n",
    "                                # select dataframe column\n",
    "        #print(\"SELECT\")\n",
    "        if bp_filtered=='yes':\n",
    "            if duration_method=='stretched':\n",
    "                specs = spec_df.raw_specs_filtered_stretched.copy()\n",
    "            else:\n",
    "                specs = spec_df.raw_specs_filtered.copy()\n",
    "        else:\n",
    "            if duration_method=='stretched':\n",
    "                specs = spec_df.raw_specs_stretched.copy()\n",
    "            else:\n",
    "                specs = spec_df.raw_specs.copy()\n",
    "    except:\n",
    "        print(\"FAILED SELECT: \", get_param_string())\n",
    "\n",
    "\n",
    "\n",
    "    try:                            # Mel transform\n",
    "        #print(\"n_mels\")\n",
    "        if n_mels>0:\n",
    "            #print(\"LAGGA\")\n",
    "            srs = spec_df.samplerate_hz.copy()\n",
    "            specs = [librosa.feature.melspectrogram(S=s, sr=sr, n_mels=n_mels, fmax=FMAX) for s, sr in zip(specs, srs)]\n",
    "        else:\n",
    "                                    # Problem: Because of the varying samplerate, the non-mel-transformed spectrograms are not all of the same height!!\n",
    "                                    # So if I'm using them, I need to cut the ones with the more frequency range.\n",
    "            #print(\"SMALLE\")\n",
    "            n_bins = [s.shape[0] for s in specs]\n",
    "            min_bins = np.min(n_bins)\n",
    "            specs = [s[0:min_bins,:] for s in specs]\n",
    "        #print(\"NEMELS\")\n",
    "    except:\n",
    "        print(\"FAILED MEL: \", get_param_string())\n",
    "\n",
    "        \n",
    "    try:\n",
    "                                # Spectrogram intensity unit\n",
    "        #print(\"UNIT\")\n",
    "        if f_unit==\"dB\":\n",
    "            specs = [librosa.power_to_db(s, ref=np.max) for s in specs]\n",
    "\n",
    "    except:\n",
    "        print(\"FAILED INTENSITY UNIT: \", get_param_string())\n",
    "\n",
    "                                # Denoising\n",
    "    if denoise=='yes':\n",
    "        specs = [(s-np.median(s, axis=0)) for s in specs]\n",
    "\n",
    "    try: \n",
    "        #print(\"OPREPRO\")# Pre-processing\n",
    "        if preprocess_type=='zs':\n",
    "            specs = [calc_zscore(s) for s in specs]\n",
    "        elif preprocess_type=='zs-fl-ce':\n",
    "            specs = [calc_zscore(s) for s in specs] \n",
    "            specs = [np.where(s<0,0,s) for s in specs]\n",
    "            specs = [np.where(s>3,3,s) for s in specs]\n",
    "\n",
    "    except:\n",
    "        print(\"FAILED PREPROCESS: \", get_param_string())\n",
    "\n",
    "    \n",
    "    try:\n",
    "        #print(\"trnasform\")\n",
    "        n_bins = specs[0].shape[0]\n",
    "        maxlen = np.max([spec.shape[1] for spec in specs]) * n_bins + 2\n",
    "        trans_specs = [pad_transform_spectro(spec, maxlen) for spec in specs]\n",
    "        data = np.asarray(trans_specs)\n",
    "    except:\n",
    "        print(\"FAILED DATA PREP: \", get_param_string())\n",
    "\n",
    "\n",
    "\n",
    "                                    # set spec_dist depending on metric_type!!\n",
    "    if metric_type=='euclidean':\n",
    "        @numba.njit()\n",
    "        def spec_dist(a,b,size):\n",
    "            dist = np.sqrt((np.sum(np.subtract(a,b)*np.subtract(a,b)))) / np.sqrt(size)\n",
    "            return dist\n",
    "\n",
    "    elif metric_type=='manhattan':\n",
    "        @numba.njit()\n",
    "        def spec_dist(a,b,size):\n",
    "            dist = (np.sum(np.abs(np.subtract(a,b)))) / size\n",
    "            return dist\n",
    "\n",
    "    elif metric_type=='cosine':\n",
    "        @numba.njit()\n",
    "        def spec_dist(a,b,size):\n",
    "                                            # turn into unit vectors by dividing each vector field by magnitude of vector\n",
    "            dot_product = np.sum(a*b)\n",
    "            a_magnitude = np.sqrt(np.sum(a*a))\n",
    "            b_magnitude = np.sqrt(np.sum(b*b))\n",
    "            if (a_magnitude*b_magnitude)==0:\n",
    "                dist=0\n",
    "            else:\n",
    "                dist = 1 - dot_product/(a_magnitude*b_magnitude)\n",
    "            return dist\n",
    "\n",
    "    elif metric_type=='correlation':\n",
    "        @numba.njit()\n",
    "        def spec_dist(a,b,size):\n",
    "            a_meandiff = a - np.mean(a)\n",
    "            b_meandiff = b - np.mean(b)\n",
    "            dot_product =  np.sum(a_meandiff*b_meandiff)                                  \n",
    "            a_meandiff_magnitude = np.sqrt(np.sum(a_meandiff*a_meandiff))\n",
    "            b_meandiff_magnitude = np.sqrt(np.sum(b_meandiff*b_meandiff))\n",
    "            if (a_meandiff_magnitude * b_meandiff_magnitude)==0:\n",
    "                dist = 0\n",
    "            else:\n",
    "                dist = 1 - dot_product/(a_meandiff_magnitude * b_meandiff_magnitude)\n",
    "            return dist\n",
    "            \n",
    "            \n",
    "            \n",
    "    if duration_method=='timeshift-overlap':\n",
    "        #print(\"CHEFDDF\")\n",
    "        @numba.njit()\n",
    "        def calc_timeshift(a,b):\n",
    "            spec_s, spec_l = unpack_specs(a,b)  \n",
    "            len_l = spec_l.shape[1]\n",
    "            len_s = spec_s.shape[1]\n",
    "\n",
    "\n",
    "                                                # define start position\n",
    "            min_overlap_frames = int(MIN_OVERLAP * len_s)\n",
    "            start_timeline = min_overlap_frames-len_s\n",
    "            max_timeline = len_l - min_overlap_frames\n",
    "\n",
    "            n_of_calculations = (max_timeline+1-start_timeline)+(max_timeline+1-start_timeline)\n",
    "\n",
    "            distances = np.full((n_of_calculations),999.)\n",
    "\n",
    "            count=0\n",
    "\n",
    "            for timeline_p in range(start_timeline, max_timeline+1):\n",
    "                                                    # mismatch on left side\n",
    "                if timeline_p < 0:\n",
    "                    start_col_l = 0\n",
    "                    len_overlap = len_s - abs(timeline_p)\n",
    "\n",
    "                    end_col_l = start_col_l + len_overlap\n",
    "\n",
    "                    end_col_s = len_s # until the end\n",
    "                    start_col_s = end_col_s - len_overlap\n",
    "\n",
    "                                                    # mismatch on right side\n",
    "                elif timeline_p > (len_l-len_s):\n",
    "                    start_col_l = timeline_p\n",
    "                    len_overlap = len_l - timeline_p\n",
    "                    end_col_l = len_l\n",
    "\n",
    "                    start_col_s = 0\n",
    "                    end_col_s = start_col_s + len_overlap\n",
    "\n",
    "                                                    # no mismatch on either side\n",
    "                else:\n",
    "                    start_col_l = timeline_p\n",
    "                    len_overlap = len_s\n",
    "                    end_col_l = start_col_l + len_overlap\n",
    "\n",
    "                    start_col_s = 0\n",
    "                    end_col_s = len_s # until the end\n",
    "\n",
    "\n",
    "                s_s = spec_s[:,start_col_s:end_col_s].astype(np.float64)\n",
    "                s_l = spec_l[:,start_col_l:end_col_l].astype(np.float64)\n",
    "                size = s_s.shape[0]*s_s.shape[1]\n",
    "                distances[count] = spec_dist(s_s, s_l, size)\n",
    "\n",
    "                count = count + 1\n",
    "\n",
    "            min_dist = np.min(distances)                                              \n",
    "            return min_dist\n",
    "                \n",
    "        try:\n",
    "            calc_umap(data, outname=outname, metric = calc_timeshift)\n",
    "        except:\n",
    "            print(\"FAILED UMAP: \", get_param_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
